```{r library}
library(igraph)
library(devtools)
```

```{r functions}
load_all()


seq=herpesvirus$PROBE_SEQUENCE
```

```{r minmash results}
test=minhash(seq[1:1000],2,50)
dist.matrix=test$dist_matrix

# firs function should create a network
# second function should cluster the network

netcluster<-function(pepmat,igraph_mode="upper",igraph_weight=TRUE,louvain_resolution=1.05){
  if(nrow(pepmat)!=ncol(pepmat)) {
    stop("Input must be a square pairwise similarity matrix")
  }
  network<-igraph::graph_from_adjacency_matrix(pepmat,mode=igraph_mode,weighted=igraph_weight)
  cluster<-igraph::cluster_louvain(network,weights=igraph::E(network),resolution=louvain_resolution)
  return(cluster$membership)
}
netcluster(dist.matrix)



test.cluster=igraph::cluster_louvain(test.net,weights = igraph::E(test.net),resolution=2)

plot(test.cluster,test.net)
test.cluster$membership

#function should take array of peptide in
# then convert to similarity matrix
# then cluster
# then check cluster size
# then iterate
clusterbreak<-function(pep,k_size=2,hash_size=50,size_max=10,size_min=3,max_itr=10,sens=1.05,cnt){
  # pep=seq[1:1000]
  
  if(size_max<=size_min){
    stop("size_max must be greater than size_min")
  }
  # cnt<<-cnt+1
  if(cnt==1){
    out.df<<-matrix(nrow = 0, ncol = 2)
    itr<<-1
  }else if(itr<=max_itr & cnt>1){
    itr<<-itr+1
  }else if(cnt>max_itr){
    return(out.df)
    stop("Maximum iteration reached without meeting required cluster size. Consider increasing size_max, max_itr, or sens")
    
  }

  pep.sim<-minhash(pep,k_size,hash_size) #minhash similarity matrix
  c.index<-netcluster(pep.sim$dist_matrix,louvain_resolution=sens) #cluster id
  pep.ref<-cbind(pep,c.index) #combine cluster id with sequences
  
  
  c.size<-tabulate(c.index) # count each cluster size
  id.itr<-which(c.size>size_max) # cluster id above max size
  id.rm<-which(c.size<size_max) # cluster id below min size
  if(length(id.itr)==0){ # if all under maximum length
    out.pep<-pep.ref[!pep.ref[,2] %in% id.rm,] # remove records in cluster with below min size
    out.pep[,2]<-paste0(cnt,".",out.pep[,2]) # combine iteration number with cluster id
    out.df<<-rbind(out.df,out.pep) # output for this level
  }else{
    #filter clusters with wanted size
    pep.out=pep.ref[(!pep.ref[,2] %in% id.rm)&(!pep.ref[,2] %in% id.itr),] #filter
    if (nrow(pep.out)>0){# check if wanted size cluster exist
      pep.out[,2]<-paste0(cnt,".",pep.out[,2]) # if there are, output
      out.df<<-rbind(out.df,pep.out)
    }
    
    #further break down others
    pep.new=pep.ref[pep.ref[,2] %in% id.itr,] # filter clusters needed to be broken down
    loop.lvl=unique(pep.new[,2]) #check how many clusters remain
    
    #loop
    for (i in 1:length(loop.lvl)){
      print(paste0("iteration ",itr," cnt ",cnt," cluster " ,i))
      sub.df<-pep.new[pep.new[,2]==loop.lvl[i],1]
      clusterbreak(pep,k_size,hash_size,size_max,size_min,max_itr,cnt=cnt+1)
    }
    return(out.df)
  }
}


```

```{r}
clusterbreak <- function(pep, k_size=2, hash_size=50, size_max=20, size_min=3, 
                        max_itr=10, sens=1.05, max_calls=100) {
  
  # Create environment to store state
  if (!exists("state")) {
    state <- new.env()
    state$out.df <- matrix(nrow = 0, ncol = 2)
    state$itr <- 1
    state$call_count <- 0
    state$clusters_processed <- 0
  }
  
  # Increment call counter
  state$call_count <- state$call_count + 1
  
  # Create helper function for logging
  log_message <- function(msg, level="INFO") {
    timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
    cat(sprintf("[%s] %s: %s\n", timestamp, level, msg))
  }
  
  # Validation checks
  if (size_max <= size_min) {
    stop("size_max must be greater than size_min")
  }
  
  # Check termination conditions
  if (state$call_count > max_calls) {
    log_message("Maximum number of function calls reached", "WARNING")
    return(state$out.df)
  }
  
  if (state$itr > max_itr) {
    log_message("Maximum iterations reached", "WARNING")
    return(state$out.df)
  }
  
  # Check for empty or invalid input
  if (length(pep) == 0) {
    log_message("Empty input sequence", "WARNING")
    return(state$out.df)
  }
  
  # Log current state
  log_message(sprintf("Starting iteration %d (call %d)", state$itr, state$call_count))
  
  # Compute similarities
  tryCatch({
    pep.sim <- minhash(pep, k_size, hash_size)
    c.index <- netcluster(pep.sim$dist_matrix, louvain_resolution=sens)
  }, error = function(e) {
    log_message(sprintf("Error in clustering: %s", e$message), "ERROR")
    return(state$out.df)
  })
  
  # Combine results
  pep.ref <- cbind(pep, c.index)
  c.size <- tabulate(c.index)
  
  # Identify clusters to process
  id.itr <- which(c.size > size_max)
  id.rm <- which(c.size < size_min)
  
  # Process results
  if (length(id.itr) == 0) {
    # All clusters under maximum size
    out.pep <- pep.ref[!pep.ref[,2] %in% id.rm,]
    if (nrow(out.pep) > 0) {
      out.pep[,2] <- paste0(state$itr, ".", out.pep[,2])
      state$out.df <- rbind(state$out.df, out.pep)
      state$clusters_processed <- state$clusters_processed + nrow(out.pep)
    }
  } else {
    # Process clusters of acceptable size
    pep.out <- pep.ref[(!pep.ref[,2] %in% id.rm) & (!pep.ref[,2] %in% id.itr),]
    if (nrow(pep.out) > 0) {
      pep.out[,2] <- paste0(state$itr, ".", pep.out[,2])
      state$out.df <- rbind(state$out.df, pep.out)
      state$clusters_processed <- state$clusters_processed + nrow(pep.out)
    }
    
    # Process remaining clusters that need further breaking down
    pep.new <- pep.ref[pep.ref[,2] %in% id.itr,]
    loop.lvl <- unique(pep.new[,2])
    
    # Recursive processing of remaining clusters
    for (i in seq_along(loop.lvl)) {
      if (state$call_count >= max_calls) {
        log_message("Maximum calls reached during loop", "WARNING")
        break
      }
      
      log_message(sprintf("Processing sub-cluster %d/%d in iteration %d", 
                         i, length(loop.lvl), state$itr))
      
      sub.df <- pep.new[pep.new[,2] == loop.lvl[i], 1]
      state$itr <- state$itr + 1
      
      # Recursive call
      clusterbreak(sub.df, k_size, hash_size, size_max, size_min, 
                  max_itr, sens, max_calls)
    }
  }
  
  # Final status report
  if (state$call_count == 1) {
    log_message(sprintf("Processing complete. Total clusters: %d, Calls: %d", 
                       state$clusters_processed, state$call_count))
  }
  
  return(state$out.df)
}

result=clusterbreak(seq[1:500])
```
```{r v3}
clusterbreak <- function(pep, k_size=2, hash_size=50, size_max=10, size_min=3, 
                        max_itr=10, sens=1.05, max_calls=100) {
  
  cluster_recursive <- function(pep) {
    # Increment call counter
    state$call_count <- state$call_count + 1
    
    # Create helper function for logging
    # generated from Claude AI prompt
    log_message <- function(msg, level="INFO") {
      timestamp <- format(Sys.time(), "%H:%M:%S")
      cat(sprintf("[%s] %s: %s\n", timestamp, level, msg))
    }
    
    # Check termination conditions
    if (state$call_count > max_calls) {
      log_message("Maximum number of function calls reached", "WARNING")
      return(state$out.df)
    }
    
    if (state$itr > max_itr) {
      log_message("Maximum iterations reached", "WARNING")
      return(state$out.df)
      break
    }
    
    # Check for empty or invalid input
    if (length(pep) == 0) {
      log_message("Empty input sequence", "WARNING")
      return(state$out.df)
    }
    
    # Log current state
    log_message(sprintf("Starting iteration %d (call %d)", state$itr, state$call_count))
    
    # Compute similarities
    tryCatch({
      pep.sim <- minhash(pep, k_size, hash_size)
      c.index <- netcluster(pep.sim$dist_matrix, louvain_resolution=sens)
    }, error = function(e) {
      log_message(sprintf("Error in clustering: %s", e$message), "ERROR")
      return(state$out.df)
    })
    
    # Combine results
    pep.ref <- cbind(pep, c.index)
    c.size <- tabulate(c.index)
    
    # Identify clusters to process
    id.itr <- which(c.size > size_max)
    id.rm <- which(c.size < size_min)
    
    # Process results
    if (length(id.itr) == 0) {
      # All clusters under maximum size
      out.pep <- pep.ref[!pep.ref[,2] %in% id.rm,]
      if (nrow(out.pep) > 0) {
        out.pep[,2] <- paste0(state$itr, ".", out.pep[,2])
        state$out.df <- rbind(state$out.df, out.pep)
        state$clusters_processed <- state$clusters_processed + nrow(out.pep)
      }
    } else {
      # Process clusters of acceptable size
      pep.out <- pep.ref[(!pep.ref[,2] %in% id.rm) & (!pep.ref[,2] %in% id.itr),]
      if (nrow(pep.out) > 0) {
        pep.out[,2] <- paste0(state$itr, ".", pep.out[,2])
        state$out.df <- rbind(state$out.df, pep.out)
        state$clusters_processed <- state$clusters_processed + nrow(pep.out)
      }
      
      # Process remaining clusters that need further breaking down
      pep.new <- pep.ref[pep.ref[,2] %in% id.itr,]
      loop.lvl <- unique(pep.new[,2])
      
      # Recursive processing of remaining clusters
      for (i in seq_along(loop.lvl)) {
        if (state$call_count >= max_calls) {
          log_message("Maximum calls reached during loop", "WARNING")
          break
        }
        
        log_message(sprintf("Processing sub-cluster %d/%d in iteration %d", 
                           i, length(loop.lvl), state$itr))
        
        sub.df <- pep.new[pep.new[,2] == loop.lvl[i], 1]
        state$itr <- state$itr + 1
        
        # Recursive call
        cluster_recursive(sub.df)
      }
    }
    
    return(state$out.df)
  }
  
  # Validation checks
  if (size_max <= size_min) {
    stop("size_max must be greater than size_min")
  }
  
  # Create new state environment for this run
  state <- new.env()
  state$out.df <- matrix(nrow = 0, ncol = 2)
  state$itr <- 1
  state$call_count <- 0
  state$clusters_processed <- 0
  
  # Run clustering
  result <- cluster_recursive(pep)
  
  # Final status report
  cat(sprintf("\nClustering complete:\n"))
  cat(sprintf("Total clusters processed: %d\n", state$clusters_processed))
  cat(sprintf("Total function calls: %d\n", state$call_count))
  cat(sprintf("Final iteration: %d\n", state$itr))
  
  # Clean up state
  rm(state)
  
  return(result)
}

clusterbreak(pep=seq[1:1000])
```

```{r v4}
clusterbreak <- function(pep, k_size=2, hash_size=50, size_max=10, size_min=3, 
                        sens=1.05, max_itr=500) {
  if (size_max <= size_min) {
    stop("size_max must be greater than size_min")
  }
  if (length(pep) == 0) {
    stop("empty input sequence vector")
  }
  
  cluster_recursive <- function(pep) {
    # Increment call counter
    # state$call_count <- state$call_count + 1
    
    # Create helper function for logging
    # adapted from Claude AI prompt
    log_message <- function(msg, level="INFO") {
      timestamp <- format(Sys.time(), "%H:%M:%S")
      cat(sprintf("[%s] %s: %s\n", timestamp, level, msg))
    }
    
    if (state$itr > max_itr) {
      log_message("Maximum function calls reached", "WARNING")
      state$convergence<-0 # change status to not converged since max itr reached
      return(state$out.df)
      break
    }
    
    pep.sim <- minhash(pep, k_size, hash_size)  #minhash similarity matrix
    c.index <- netcluster(pep.sim$dist_matrix, louvain_resolution=sens) #cluster id
    pep.ref <- cbind(pep, c.index) # combine cluster id with sequences
    c.size <- tabulate(c.index) # count each cluster size
    id.itr <- which(c.size > size_max) # cluster id above max size
    id.rm <- which(c.size < size_min) # cluster id below min size
    
   # stop or recursion conditions for output
    if (length(id.itr) == 0) {  
      out.pep <- pep.ref[!pep.ref[,2] %in% id.rm,] # filter out those under minimum length
      if (nrow(out.pep) > 0) { #ensure non-empty output
        out.pep[,2] <- paste0(state$itr, ".", out.pep[,2]) #combine iteration and cluster to ensure uniqueness
        state$out.df <- rbind(state$out.df, out.pep) # combine output df
        state$clusters_processed <- state$clusters_processed + nrow(out.pep) # sum number of clusters processed
      }
    } else {
      pep.out <- pep.ref[(!pep.ref[,2] %in% id.rm) & (!pep.ref[,2] %in% id.itr),] # recursion condition
      if (nrow(pep.out) > 0) {
        pep.out[,2] <- paste0(state$itr, ".", pep.out[,2])#combine iteration and cluster to ensure uniqueness
        state$out.df <- rbind(state$out.df, pep.out)# combine output df
        state$clusters_processed <- state$clusters_processed + nrow(pep.out)# sum number of clusters processed
      }

      # filter remaining clusters
      pep.new <- pep.ref[pep.ref[,2] %in% id.itr,]#clusters with size > max
      loop.lvl <- unique(pep.new[,2])#set levels for loop

      # loop for remaining qualified clusters
      for (i in seq_along(loop.lvl)) {
        sub.df <- pep.new[pep.new[,2] == loop.lvl[i], 1]
        state$itr <- state$itr + 1
        cluster_recursive(sub.df)
      }
    }
    
  # if(length(id.itr)==0){ # if all under maximum length
  #   out.pep<-pep.ref[!pep.ref[,2] %in% id.rm,] # remove records in cluster with below min size
  #   out.pep[,2]<-paste0(cnt,".",out.pep[,2]) # combine iteration number with cluster id
  #   # out.df<<-rbind(out.df,out.pep) # output for this level
  #   state$out.df <- rbind(state$out.df, out.pep)
  #   state$clusters_processed <- state$clusters_processed + length(unique(out.pep[,2])) # sum number processed
  # }else{
  #   #filter clusters with wanted size
  #   pep.out=pep.ref[(!pep.ref[,2] %in% id.rm)&(!pep.ref[,2] %in% id.itr),] #filter
  #   if (nrow(pep.out)>0){# check if wanted size cluster exist
  #     pep.out[,2]<-paste0(cnt,".",pep.out[,2]) # if there are, output
  #     # out.df<<-rbind(out.df,pep.out)
  #     state$out.df <- rbind(state$out.df, pep.out)
  #     state$clusters_processed <- state$clusters_processed + length(unique(pep.out[,2]))
  #   }
  #   
  #   #further break down others
  #   pep.new=pep.ref[pep.ref[,2] %in% id.itr,] # filter clusters needed to be broken down
  #   loop.lvl=unique(pep.new[,2]) #check how many clusters remain
  #   
  #   #loop
  #     for (i in seq_along(loop.lvl)) {
  #       sub.df <- pep.new[pep.new[,2] == loop.lvl[i], 1]
  #       state$itr <- state$itr + 1
  #       cluster_recursive(sub.df)
  #     }
  # }
    
    return(state$out.df)
  }
  


  
  # Create new state environment
  state <- new.env()
  state$out.df <- matrix(nrow = 0, ncol = 2)
  state$itr <- 1
  # state$call_count <- 0
  state$clusters_processed <- 0
  state$convergence <- 1
  
  # run recursive clustering
  result <- cluster_recursive(pep)
  
  # Final status report adapted from claude AI output
  if (state$convergence==1){
    cat(sprintf("\nClustering complete:\n"))
  }else{
    cat(sprintf("\nClustering incomplete, consider adjust parameters:\n"))
  }
  cat(sprintf("Total clusters processed: %d\n", state$clusters_processed))
  cat(sprintf("Total function calls: %d\n", state$itr))

  
  # Clean up state
  rm(state)
  
  return(result)
}

test=clusterbreak(pep=seq[1:100])
```

```{r function_documentation}
#' seqnetcluster
#'
#' @param x A vector of values.
#' @param n Number to multiply by.
#' @return A clustered graph network 
#' @importFrom igraph graph_from_adjacency_matrix E cluster_louvain
#' @export

```

