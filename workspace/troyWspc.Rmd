```{r library}

rm(list=ls())
```

```{r functions}
load_all()

seq=herpesvirus$PROBE_SEQUENCE
```

```{r testing}
# load main package
# library(DynaAlign)
# library(devtools)
load_all()

################################################################################
# evaluate similarity matrix generation
library(DECIPHER)
library(dplyr)
library(tidyr)
library(stringr)
library(microbenchmark)
library(ggplot2)
library(mclust)
 library(viridis)
######
# load testing datasets
## short ~12aa
testpep <- herpesvirus
testpep$SEQ_VIRUS <- stringr::str_split_fixed(testpep$SEQ_INFO,"\\|",4)[,3]
set.seed(2024)
testpep <- testpep %>% dplyr::distinct(PROBE_SEQUENCE,.keep_all = T) %>% 
  dplyr::group_by(SEQ_VIRUS) %>% dplyr::sample_frac(.008)
## long ~560aa
set.seed(2024)
testha <- h3n2sample %>% dplyr::group_by(clade) %>% dplyr::sample_frac(.008) %>% dplyr::ungroup()
testha <- testha %>% dplyr::distinct(sequence,.keep_all=T)
######
# generat similarity matrices for short dataset

# function to evaluate pearson correlation between different methods
## DECIPHER 
testpep.aa <- AAStringSet(testpep$PROBE_SEQUENCE)
testpep.aa <- AlignSeqs(testpep.aa)
testpep.aa.DM <- DistanceMatrix(testpep.aa)
padec.matrix <- 1 - as.matrix(testpep.aa.DM)
## pairwise 
pa.matrix <- similarityNW(testpep$PROBE_SEQUENCE)


cor_eval_mh_rmh <- function(seq,pa.in,padec,k.mh,n.mh){

  mh.matrix <- similarityMH(seq,k=k.mh,n_hash=n.mh) # rcpp min hash
  rmh.matrix <- 1-minhash(seq,k=k.mh,n_hash=n.mh)$dist_matrix# R min hash
  
  pa.in <- pa.in[upper.tri(pa.in)]
  padec <- padec[upper.tri(padec)]
  mh.matrix <- mh.matrix[upper.tri(mh.matrix)]
  pa.matrix <- pa.matrix[upper.tri(pa.matrix)]
  rmh.matrix <- rmh.matrix[upper.tri(rmh.matrix)]
  
  return(c(cor(pa.in,padec,method = "pearson", use = "complete.obs"),
           cor(mh.matrix,rmh.matrix,method = "pearson"),
           cor(pa.in,mh.matrix,method = "pearson"),        
           cor(padec,mh.matrix,method = "pearson",use = "complete.obs")
           ))
}

k.input=4
short.sim.result=t(replicate(50,cor_eval_mh_rmh(testpep$PROBE_SEQUENCE,pa.matrix,padec.matrix,k.input,50)))
short.sim.result.summary=as.data.frame(short.sim.result) %>% 
  summarise( 
    mean.pa_padec = mean(.[[1]]),
    sd.pa_padec = sd(.[[1]]),
    mean.mh_rmh = mean(.[[2]]),
    sd.mh_rmh = sd(.[[2]]),
    mean.pa_mh = mean(.[[3]]),
    sd.pa_mh = sd(.[[3]]),
    mean.padec_mh = mean(.[[4]]),
    sd.padec_mh = sd(.[[4]]),
    )
write.csv(short.sim.result.summary,paste0("C:/Users/chowz/OneDrive/umich/2024 Fall/BIOS 615/final project/output/short_correlation_summ_k_",k.input,".csv"),row.names = F)


short.sim.result.plot=as.data.frame(short.sim.result)
colnames(short.sim.result.plot)=c("pa_padec","mh_rmh","pa_mh","padec_mh")
short.sim.result.plot=short.sim.result.plot %>% pivot_longer(cols=c(1:4),names_to="comparison",values_to="cor")
short.sim.result.plot.gg=ggplot(short.sim.result.plot, aes(x = comparison, y = cor)) +
  geom_boxplot() + theme_classic()+geom_jitter(width = 0.2, alpha = 0.1, color = "blue") +  
  labs(x = "comparison", y = "Pearson correlation coefficient")+
  scale_y_continuous(limits=c(0,1),n.breaks=6)

ggsave(paste0("C:/Users/chowz/OneDrive/umich/2024 Fall/BIOS 615/final project/output/short_correlation_summ_k_",k.input,"_plot.png"), plot = short.sim.result.plot.gg, width = 5, height = 5, dpi = 300)

###
# for longer sequences
## DECIPHER 
testpep.aa.l <- AAStringSet(testha$sequence)
testpep.aa.l <- AlignSeqs(testpep.aa.l)
testpep.aa.DM.l <- DistanceMatrix(testpep.aa.l)
padec.matrix.l <- 1 - as.matrix(testpep.aa.DM.l)
## pairwise 
pa.matrix.l <- similarityNW(testha$sequence,matrixName = "BLOSUM80")


k.input=3
long.sim.result=t(replicate(50,cor_eval_mh_rmh(testha$sequence,pa.matrix.l,padec.matrix.l,k.input,600)))
long.sim.result.summary=as.data.frame(long.sim.result) %>% 
  summarise( 
    mean.pa_padec = mean(.[[1]]),
    sd.pa_padec = sd(.[[1]]),
    mean.mh_rmh = mean(.[[2]]),
    sd.mh_rmh = sd(.[[2]]),
    mean.pa_mh = mean(.[[3]]),
    sd.pa_mh = sd(.[[3]]),
    mean.padec_mh = mean(.[[4]]),
    sd.padec_mh = sd(.[[4]]),
    )
write.csv(long.sim.result.summary,paste0("C:/Users/chowz/OneDrive/umich/2024 Fall/BIOS 615/final project/output/long_correlation_summ_k_",k.input,".csv"),row.names = F)
# microbenchmark(similarityMH(testpep$PROBE_SEQUENCE,k=2,n_hash=50),
#                 similarityNW(testpep$PROBE_SEQUENCE),
#                minhash(testpep$PROBE_SEQUENCE,k=2,n_hash=50))

long.sim.result.plot=as.data.frame(long.sim.result)
colnames(long.sim.result.plot)=c("pa_padec","mh_rmh","pa_mh","padec_mh")
long.sim.result.plot=long.sim.result.plot %>% pivot_longer(cols=c(1:4),names_to="comparison",values_to="cor")
long.sim.result.plot.gg=ggplot(long.sim.result.plot, aes(x = comparison, y = cor)) +
  geom_boxplot() + theme_classic()+geom_jitter(width = 0.2, alpha = 0.1, color = "blue") +  
  labs(x = "comparison", y = "Pearson correlation coefficient")+
  scale_y_continuous(limits=c(-1,1),n.breaks=12)
ggsave(paste0("C:/Users/chowz/OneDrive/umich/2024 Fall/BIOS 615/final project/output/long_correlation_summ_k_",k.input,"_plot.png"), plot = long.sim.result.plot.gg, width = 5, height = 5, dpi = 300)
################################################################################
# classification

      ##explore short data
      testpep.s<- herpesvirus
      testpep.s$SEQ_VIRUS <- stringr::str_split_fixed(testpep.s$SEQ_INFO,"\\|",4)[,3]
      set.seed(2024)
      testpep.s <- testpep.s %>% dplyr::distinct(PROBE_SEQUENCE,.keep_all = T) %>% 
        dplyr::group_by(SEQ_VIRUS) %>% dplyr::sample_frac(.1)
      testpep.s.clus=clusterbreak(testpep.s$PROBE_SEQUENCE,
                                size_max = 2500,
                                size_min=2,
                                thresh_p=.7,
                                sim_fn=function(x) similarityMH(x,k=1,n_hash=50))
      # ari measure code is AI generated by chatgpt
      #create confusion matrix
      confusionmatrix.s <- testpep.s.clus$clustered_seq
      testdf.conf.s <- testpep.s %>% dplyr::select(PROBE_SEQUENCE,SEQ_VIRUS)
      colnames(testdf.conf.s)[1]="pep"
      confusionmatrix.s <- dplyr::left_join(as.data.frame(confusionmatrix.s),testdf.conf.s,by="pep")
      adjustedRandIndex(confusionmatrix.s$SEQ_VIRUS, confusionmatrix.s$c.index)
      
      
### long data
testclass <- h3n2sample
testclass <- testclass %>% dplyr::distinct(sequence,.keep_all=T)
class_eval=function(seq){

test.cluster=clusterbreak(seq,
                          size_max = 2500,
                          size_min=10,
                          thresh_p=.7,
                          sim_fn=function(x) similarityMH(x,k=3,n_hash=600))

# ari measure code is AI generated by chatgpt
#create confusion matrix
confusionmatrix <- test.cluster$clustered_seq
testdf.conf <- h3n2sample %>% dplyr::select(sequence,clade)
colnames(testdf.conf)[1]="pep"
confusionmatrix <- dplyr::left_join(as.data.frame(confusionmatrix),testdf.conf,by="pep")
adjustedRandIndex(confusionmatrix$clade, confusionmatrix$c.index)

return(adjustedRandIndex(confusionmatrix$clade, confusionmatrix$c.index))
}



class.results<-NULL
for (i in 1:1000){#rep does not work for this somehow
  print(paste0(i,"/1000"))
  class.results=c(class.results,class_eval(testclass$sequence))
}
mean(class.results)
sd(class.results)
max(class.results)
write.csv(class.results,paste0("C:/Users/chowz/OneDrive/umich/2024 Fall/BIOS 615/final project/output/long_classification_ari_rep1000.csv"),row.names = F)
#plot the confusion matrix
conf.plot=confusionmatrix
conf.plot=conf.plot %>% group_by(c.index,clade) %>% summarise(freq=n())
conf.plot$perc <- conf.plot$freq / sum(conf.plot$freq) * 100
conf.plot.truth=conf.plot
conf.plot.truth=conf.plot.truth %>% group_by(clade) %>% summarise(freq=sum(freq))
conf.plot.truth$perc=conf.plot.truth$freq/sum(conf.plot.truth$freq)*100
conf.plot.truth$c.index="truth"

conf.plot=rbind(conf.plot,conf.plot.truth)

 #claude generated code for visualization
  #adjusted
ggplot(conf.plot, aes(x = c.index, y = clade, fill = freq)) +
    geom_tile(color = "white") +
    scale_fill_viridis_c(name = "Frequency") +
    geom_text(aes(label = sprintf("%d", freq)), 
              color = "white", fontface = "bold") +
    theme_classic() +
    labs(x = "Clusters", y = "Clade")+  theme(
      # Bold axis titles
      axis.title.x = element_text(face = "bold", size = 12),
      axis.title.y = element_text(face = "bold", size = 12),
      
      # Bold and angled axis labels
      axis.text.x = element_text(face = "bold"),
      axis.text.y = element_text(face = "bold"),
      
      # Bold plot title
      plot.title = element_text(face = "bold", hjust = 0.5),
      
      # Legend styling
      legend.title = element_text(face = "bold")
    )

ggplot(conf.plot, aes(x = c.index, y = clade, fill = perc)) +
    geom_tile(color = "white") +
    scale_fill_viridis_c(name = "Percentage (%)", 
                         labels = function(x) sprintf("%.1f%%", x)) +
    geom_text(aes(label = sprintf("%.1f%%", perc)), 
              color = "white", fontface = "bold") +
    theme_minimal() +
    labs(title = "Confusion Matrix - Percentage",
         x = "Predicted Class",
         y = "True Class")


#generate consensus sequence
conc=clusterconsensus(test.cluster$clustered_seq)

#generate consensus plot
consensusplot(conc, vertex.size=0,edge.width=NA)

```


```{r function revamp}
set.seed(2024)

#read in sample H3N2 sequences
# load("data/h3n2sample.rda")
testha <- h3n2sample %>% dplyr::group_by(clade) %>% dplyr::sample_frac(.008) %>% dplyr::ungroup()
testha <- testha %>% dplyr::distinct(sequence,.keep_all=T)

#load short sequence
testdf <- herpesvirus
testdf$SEQ_VIRUS <- stringr::str_split_fixed(testdf$SEQ_INFO,"\\|",4)[,3]
testdf <- testdf %>% dplyr::distinct(PROBE_SEQUENCE,.keep_all = T) %>% 
  dplyr::group_by(SEQ_VIRUS) %>% dplyr::sample_frac(.02)

mh.matrix <- similarityMH(testdf$PROBE_SEQUENCE,k=2,n_hash=50) # rcpp min hash
pa.matrix <- similarityNW(testdf$PROBE_SEQUENCE) # rcpp pairwise alignment
rmh.matrix <- minhash(testdf$PROBE_SEQUENCE,k=1,n_hash=50)$dist_matrix# R min hash

mh.matrix.ha <- similarityMH(testha$sequence,k=3,n_hash=500) # rcpp min hash
pa.matrix.ha <- similarityNW(testha$sequence,matrixName = "BLOSUM80") # rcpp pairwise alignment
rmh.matrix.ha <- minhash(testha$sequence,k=3,n_hash=500)$dist_matrix# R min hash

cor(rmh.matrix.ha[upper.tri(rmh.matrix.ha)], 
                   pa.matrix.ha[upper.tri(pa.matrix.ha)],
                   method = "pearson")

# AI generated code for correlation testing 
  library(vegan)  # For Mantel test
  library(ade4)   # Alternative correlation method
  library(ggplot2)
  # Mantel test (most common method)
  mantel_result <- mantel(mh.matrix, pa.matrix)
  mantel_result
  
  cor(mh.matrix[upper.tri(mh.matrix)], 
                   pa.matrix[upper.tri(pa.matrix)],
                   method = "pearson")
  
  pearson_cor <- cor(mh.matrix[upper.tri(mh.matrix)], 
                   pa.matrix[upper.tri(pa.matrix)],
                   method = "pearson")
  mantel_partial <- mantel.partial(mh.matrix, pa.matrix, rmh.matrix)
  # Print Mantel test results
  print(mantel_result)
  
  #plot
  plot_data <- data.frame(
                  dist1 = as.vector(mh.matrix[upper.tri(mh.matrix)]),
                  dist2 = as.vector(pa.matrix[upper.tri(pa.matrix)]))
  correlation_plot <- ggplot(plot_data, aes(x = dist1, y = dist2)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "red") +
  labs(
    title = "Correlation Between Distance Matrices",
    subtitle = paste("Mantel r =", round(mantel_result$statistic, 3), 
                     "p =", round(mantel_result$signif, 3)),
    x = "Distance Matrix 1",
    y = "Distance Matrix 2"
  ) +
  theme_minimal()

  
  
  
#revamp functions
#use mh.matrix


netcluster<-function(pepmat,
                     igraph_mode = "upper",
                     igraph_weight = TRUE,
                     cluster_func = function(x,...) igraph::cluster_louvain(x,
                                                                resolution=1.05,...)$membership,
                     cluster_weight = TRUE) {
  if(nrow(pepmat)!=ncol(pepmat)) {
    stop("Input must be a square pairwise similarity matrix")
  }

  network<-igraph::graph_from_adjacency_matrix(pepmat,
                                               mode=igraph_mode,
                                               weighted=igraph_weight) #construct network
  if (cluster_weight){
    out <- cluster_func(network,weights=igraph::E(network)$weight) #include network weight in cluster function
  }else{
    out <- cluster_func(network)
  }
  
  if (is.numeric(out) && is.vector(out)){
    return(out)
  }else{
    stop("Wrong clustering output format. Output should be a numeric vector of cluster assignment.")
  }
}

# ltest=cluster_louvain(network,res=1)

fn.test=netcluster(mh.matrix,cluster_weight=F,cluster_func=function(x,...) louvain_mod(gin=x,res=1.05,...)$cluster)

test.check=function(fn1,fn2,...){
  return(identical(fn1,fn2,...))
}

test.check(cluster_louvain,function(x) cluster_louvain(x,res=1.05),ignore.bytecode=T)
```


#relic code

```{r revamp_clusterbreak}
# clusterbreak <- function(pep, 
#                          thresh = 0.8,
#                          k_size = 2, hash_size = 50, 
#                          size_max = 10, 
#                          size_min = 3, 
#                          sens = 1.05, 
#                          max_itr = 10000) 

###### set debug param

# thresh_p = 0.8
#                         
#                          size_max = 10 
#                          size_min = 3
#                          
#                          max_itr = 10000
#                          sim_fn=function(x) similarityMH(x,k=2,n_hash=50)
#                          cluster_fn=function(x,...) igraph::cluster_louvain(x,
#                                                                 resolution=1.05,...)$membership
#                          cluster_wt=TRUE
clusterbreak <- function(pep, 
                         thresh_p = 0.8,
                         # k_size = 2, hash_size = 50, 
                         size_max = 10, 
                         size_min = 3, 
                         # sens = 1.05, 
                         max_itr = 10000,
                         sim_fn=function(x) similarityMH(x,k=2,n_hash=50),
                         cluster_fn=function(x,...) igraph::cluster_louvain(x,
                                                                resolution=1.05,...)$membership,
                         cluster_wt=TRUE) {
  if (size_max <= size_min) {
    stop("size_max must be greater than size_min")
  }
  if (length(pep) == 0) {
    stop("empty input sequence vector")
  }
  
  # Create new state environment
  state <- new.env()
  state$out.df <- matrix(nrow = 0, ncol = 2)
  state$itr <- 1
  state$convergence <- 1
  state$filter.df <- NULL
  
  cluster_recursive <- function(pep) {
    
    # Create helper function for logging adapted from Claude AI prompt
    log_message <- function(msg, level="INFO") {
      timestamp <- format(Sys.time(), "%H:%M:%S")
      cat(sprintf("[%s] %s: %s\n", timestamp, level, msg))
    }
    
    if (state$itr > max_itr) {
      log_message("Maximum function calls reached", "WARNING")
      state$convergence<-0 # change status to not converged since max itr reached
      return(state$out.df)
    }
    
    pep.sim <- sim_fn(pep)  #custom function for similarity matrix generation
    
    threshold <- quantile(pep.sim[upper.tri(pep.sim)],thresh_p) #quantile based threshold
    
    pep.sim[pep.sim<threshold] <- 0 # remove edges from nodes with similarity below threshold
    c.index <- netcluster(pep.sim,cluster_func = cluster_fn,cluster_weight=cluster_wt) #cluster id
    pep.ref <- cbind(pep, c.index) # combine cluster id with sequences
    c.size <- tabulate(c.index) # count each cluster size
    id.itr <- which(c.size > size_max) # cluster id above max size
    id.rm <- which(c.size < size_min) # cluster id below min size
    
    state$filter.df <- c(state$filter.df,pep.ref[pep.ref[,2] %in% id.rm,1]) #store filtered sequences
    
    # stop or recursion conditions for output
    if (length(id.itr) == 0) {  
      out.pep <- pep.ref[!pep.ref[,2] %in% id.rm,] # filter out those under minimum length
      if (nrow(out.pep) > 0) { #ensure non-empty output
        out.pep[,2] <- paste0(state$itr, ".", out.pep[,2]) #combine iteration and cluster to ensure uniqueness
        state$out.df <- rbind(state$out.df, out.pep) # combine output df
      }
    } else {
      pep.out <- pep.ref[(!pep.ref[,2] %in% id.rm) & (!pep.ref[,2] %in% id.itr),] # recursion condition
      if (nrow(pep.out) > 0) {
        pep.out[,2] <- paste0(state$itr, ".", pep.out[,2])#combine iteration and cluster to ensure uniqueness
        state$out.df <- rbind(state$out.df, pep.out)# combine output df
        
      }
      
      # filter remaining clusters
      pep.new <- pep.ref[pep.ref[,2] %in% id.itr,]#clusters with size > max
      loop.lvl <- unique(pep.new[,2])#set levels for loop
      
      # loop for remaining qualified clusters
      for (i in seq_along(loop.lvl)) {
        sub.df <- pep.new[pep.new[,2] == loop.lvl[i], 1] #filter ith cluster
        state$itr <- state$itr + 1 #increment for iteration/function call
        cluster_recursive(sub.df) #recursive call
      }
    }
    
    return(list(clustered_seq=state$out.df,
                filtered_seq=state$filter.df))
  }
  
  # run recursive clustering
  result <- cluster_recursive(pep)
  
  # Final status report adapted from claude AI output
  if (state$convergence==1){
    cat(sprintf("\nClustering complete:\n"))
  }else{
    cat(sprintf("\nClustering incomplete, consider adjusting parameters:\n"))
  }
  cat(sprintf("Total function calls (clusters broken): %d\n", state$itr))
  
  rm(state) # reset state global 
  
  return(result)
}

test.cluster=clusterbreak(testdf$PROBE_SEQUENCE,thresh_p=.95)
# table(test.cluster[])

# test.cluster$clustered_seq

conc=clusterconsensus(test.cluster$clustered_seq)

consensusplot<-function(df,
                        k_size = 2, 
                        hash_size = 50,
                        threshold_p = 0.8,
                        sens = 1.05,...) {
  #similarity matrix and adjacency matrix
  df.hash <- minhash(df[,2], k_size, hash_size)
  df.hash <- df.hash$dist_matrix
  threshold <- quantile(df.hash[upper.tri(df.hash)],threshold_p)
  df.hash[df.hash<threshold] <- 0
  #plot call
  g <- igraph::graph_from_adjacency_matrix(df.hash, mode="upper", weighted=TRUE) # base plot
  g.weight <- igraph::E(g)$weight # edge weight
  g.cluster <- igraph::cluster_louvain(g,weights = g.weight, resolution = sens) # cluster using weights
  
  g.layout <- igraph::layout_with_fr(g, weights = g.weight) #set layout for plot
  igraph::V(g)$name <- df[,1]#set node names to cluster name
  g.out <- plot(g.cluster, g, layout = g.layout,...)
  return(g.out)
}

consensusplot(conc, vertex.size=0,edge.width=NA)


test.cluster$clustered_seq


test.cluster=clusterbreak(h3n2sample$sequence,size_max = 800,thresh_p=.8,sim_fn=function(x) similarityMH(x,k=4,n_hash=500))
```

```{r testing_purposes}
#create confusion matrix
confusionmatrix <- test.cluster$clustered_seq
# testdf.conf <- testdf %>% dplyr::select(PROBE_SEQUENCE,SEQ_VIRUS)#shorter sequence
testdf.conf <- h3n2sample %>% dplyr::select(sequence,clade)
colnames(testdf.conf)[1]="pep"
confusionmatrix <- dplyr::left_join(as.data.frame(confusionmatrix),testdf.conf,by="pep")

library(mclust)

adjustedRandIndex(confusionmatrix$clade, confusionmatrix$c.index)

library(vegan)

mutinformation(confusionmatrix$clade, confusionmatrix$c.index) / 
       sqrt(entropy(confusionmatrix$clade) * entropy(confusionmatrix$c.index))

library(ggplot2)
ggplot(confusionmatrix, aes(x = pep, y = c.index, color = clade)) +
  geom_point(size = 3) +
  labs(title = "Clusters vs True Classes")
```


```{r}

sequences <- herpesvirus$PROBE_SEQUENCE[1:500]
similarity_matrix <- similarityMH(sequences) 
threshold <- quantile(similarity_matrix,0.8) 
adjacency_matrix <- similarity_matrix 
adjacency_matrix[adjacency_matrix<threshold] <- 0 
network<-igraph::graph_from_adjacency_matrix(adjacency_matrix,mode="upper",weighted=TRUE) 
louvain_mod(network,res=1.05) 
```

